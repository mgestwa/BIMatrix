from flask import Flask, request, jsonify
from flask_cors import CORS
from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion
from semantic_kernel.prompt_template import PromptTemplateConfig, InputVariable
from semantic_kernel.functions import KernelArguments, KernelFunction, KernelPlugin
from dotenv import load_dotenv
import asyncio
import json
import logging
import os

load_dotenv()

app = Flask(__name__)
CORS(app)

# Konfiguracja Semantic Kernel
kernel = Kernel()
api_key = os.getenv("OPENAI_API_KEY")

try:
    service = OpenAIChatCompletion(
        service_id="chat-gpt",
        ai_model_id="gpt-4o",  # Upewnij siƒô, ≈ºe model jest odpowiedni dla Twojego zastosowania
        api_key=api_key
    )
    kernel.add_service(service)
    logging.info("‚úÖ Us≈Çuga OpenAI skonfigurowana!")
except Exception as e:
    logging.error(f"‚ùå B≈ÇƒÖd: {str(e)}")
    exit(1)

def run_async(coro):
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    return loop.run_until_complete(coro)

@app.route('/api/data', methods=['POST'])
def analyze_data():
    try:
        data = request.json
        logging.debug(f"Dane wej≈õciowe: {json.dumps(data, indent=2)}")
        
        # Nowy prompt, kt√≥ry:
        # Krok 1: Upraszcza dane ka≈ºdego elementu, wyodrƒôbniajƒÖc kluczowe w≈Ça≈õciwo≈õci (np. Nazwa, Typ, Wymiary, Materia≈Ç).
        # Krok 2: Na podstawie upraszczania generuje zestawienie ilo≈õciowe ‚Äì liczbƒô element√≥w, g≈Ç√≥wne typy, podsumowanie rozmiar√≥w i materia≈Ç√≥w.
        prompt_template_config = PromptTemplateConfig(
            template="""
[Jako ekspert BIM, przeanalizuj poni≈ºsze dane element√≥w IFC.]

Krok 1: Upro≈õƒá dane wej≈õciowe ‚Äì dla ka≈ºdego elementu wyodrƒôbnij kluczowe w≈Ça≈õciwo≈õci, takie jak:
  - Nazwa elementu
  - Typ (np. IFCFLOWSEGMENT, itp.)
  - Rodzina i typ
  - Wymiary (np. wielko≈õƒá, ≈õrednica)
  - Materia≈Ç

Krok 2: Na podstawie uproszczonych danych stw√≥rz zestawienie ilo≈õciowe, zawierajƒÖce:
  - Ca≈ÇkowitƒÖ liczbƒô element√≥w
  - G≈Ç√≥wne typy element√≥w wraz z ich ilo≈õciƒÖ
  - Podsumowanie rozmiar√≥w (np. ≈õrednia wielko≈õƒá lub zakres wymiar√≥w)
  - Rozk≈Çad materia≈Ç√≥w

Dane wej≈õciowe:
{{$input}}

Odpowiedz w formacie JSON.
            """,
            input_variables=[
                InputVariable(name="input", description="Dane IFC", is_required=True)
            ]
        )

        # Utworzenie funkcji na podstawie promptu
        analyze_function = KernelFunction.from_prompt(
            function_name="AnalyzeMultipleIFCElements",
            plugin_name="BIMAnalysis",
            prompt_template_config=prompt_template_config
        )

        # Utworzenie pluginu i dodanie do kernela
        plugin = KernelPlugin(name="BIMAnalysis", functions=[analyze_function])
        kernel.add_plugin(plugin)

        # Przygotowanie argument√≥w ‚Äì dane wej≈õciowe (mogƒÖ to byƒá np. lista element√≥w lub obiekt zawierajƒÖcy wiele element√≥w)
        arguments = KernelArguments(input=json.dumps(data, indent=2))

        # Wywo≈Çanie funkcji asynchronicznie
        analysis = run_async(
            kernel.invoke(function=analyze_function, arguments=arguments)
        )

        return jsonify({
            "status": "success",
            "analysis": str(analysis)
        })

    except Exception as e:
        logging.error(f"üí• B≈ÇƒÖd: {str(e)}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

if __name__ == '__main__':
    app.run(port=5000, debug=True)
